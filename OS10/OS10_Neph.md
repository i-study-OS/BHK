---
layout: post
title: "[#14] 가상 메모리"
image:
categories: 운영체제
tags: 
  - 운영체제
  - OS
sitemap:
  changefreq: daily
  priority: 1.0
---

## Demand Paging

### 요구 페이징의 원리

요구 페이징: 모든 페이지를 한꺼번에 메모리에 올리는게 아닌 당장 사용될 페이지만 올리는 방식

CPU가 특정 페이지를 요청하면 그 때 해당 페이지를 메모리에 적재

요구페이징의 이점: 메모리 사용량 감소, 메모리에 올리는데 소요되는 오버헤드 감소

어떤 페이지가 메모리에 존재하고 어떤 페이지가 스왑 영역에 존재하는지 알기 위해 페이지 테이블의 유효-무효 비트를 둠



### Page Fault  처리

Page Fault: 참조를 시도했는데 페이지 테이블의 유효-무효 비트가 "무효"인 경우에 발생하는 오류

Page Fault가 발생하면 페이지 부재 트랩이 발생하며 디스크에서 부재 페이지를 빈 프레임으로 적재하고 페이지 테이블을 업데이트 함, 이 작업은 오래걸리기 때문에 CPU 빼앗기고 봉쇄상태에 진입



### 요구 페이징의 성능

Page Fault가 적을수록 좋은 알고리즘

요구 페이징의 성능척도: 유효 접근시간

유효 접근시간 = (1-P) * 메모리 접근시간 + P * (페이지 부재 발생 처리 오버헤드 + 메모리에 빈 프레임이 없는 경우 스왑 아웃 오버헤드 + 요청된 페이지의 스왑 인 오버헤드 + 프로세스의 재시작 오버헤드)

여기서 P는 Page Fault 발생비율

## Page Replacement

페이지 부재가 발생했을 때 부재하는 페이지를 디스크로부터 읽어와서 메모리(프레임)에 적재해야 함

근데 이 때 물리적 메모리에 빈 프레임이 없을 수도 있음

이럴 때 페이지 중 하나를 디스크로 쫓아낸 뒤에 읽어와야 됨

이걸 페이지 교체라고 함



어떤 페이지를 쫓아낼건지를 결정하는 알고리즘을 교체 알고리즘이라 함



### 최적 페이지 교체

빌레디의 최적 알고리즘은 알고리즘의 성능에 대한 상한선을 제공함

빌레디의 최적 알고리즘은 미래에 어떤 페이지가 어떠한 순서로 참조될지 미리 알고 있다는 전제하에 알고리즘을 운영함

따라서 오프라인에 최적화된 알고리즘이며 온라인에는 부적합함

알고리즘의 동작 방식은 가장 먼 미래에 참조될 페이지를 내쫓는 것



### FIFO

가장 먼저 올라온 페이지를 내쫓는 알고리즘

### LRU

시간지역성: 최근에 참조된 페이지가 가까운 미래에 다시 참조될 가능성이 높은 성질

LRU 알고리즘에서는 가장 오래전에 참조된 페이지를 쫓아냄



### LFU

페이지의 참조 횟수로 교체시킬 페이지를 결정함

물리적 메모리 내에 존재하는 페이지 중 과거에 참조된 횟수가 가장 적은 것을 내쫓음

같은 횟수를 가진 것들이 있다면 상대적으로 오래 전에 참조된 것을 내쫓는 것이 효율적



LFU는 Incache-LFU와 Perfect-LFU로 나뉨

Incache-LFU는 물리적 메모리에 올라온 시점을 기준으로 1부터 count함 (내쫓기기 이전 기록 없음)

Perfect-LFU는 메모리에 올라와있는지에 관계없이 과거 이력만 가지고 내쫓을 것 선정함 (기록보관으로 인한 오버헤드 큼)



LFU는 LRU보다 오랜 시간 동안의 참조 기록을 반영할 수 있다는 장점 있음

하지만 시간에 따른 페이지 참조의 변화를 반영할 수 없고 LRU에 비해 구현이 복잡함



### Clock

LRU와 LFU는 참조 시각, 참조 횟수를 유지하고 비교해야 하므로 알고리즘의 운영에 시간적 오버헤드 발생함

클럭 알고리즘은 하드웨어의 도움을 받아 이것을 줄임

클럭 알고리즘은 LRU를 근사시킨 알고리즘으로 NotUsedRecently, NotRecentlyUsed 알고리즘이라고도 불림

최근에 참조되지 않은 페이지를 교체 대상으로 선정하는 것은 LRU와 유사하지만 교체되는 페이지의 참조 시점이 가장 오래되었다는 것을 보장하지는 못함

하지만 대신 하드웨어의 도움을 받으므로 빠르고 효율적, 이러한 이유로 대부분의 클럭 알고리즘을 사용함



클럭 알고리즘은 교체 페이지 선정을 위해 페이지 프레임들의 참조비트를 순차적으로 조사함

참조 비트는 각 프레임마다 하나씩 존재하며 참조될 때 1로 세팅됨

클럭이 돌 때 1인건 0으로 바꾸고 지나가고 0인거 발견하면 그것을 교체함

간단히 말해서 시계바늘 한바퀴 돌아가는 동안 참조 안된 페이지 있으면 그걸 교체하는 방식



## Page Frame Allocation

멀티 프로세스 환경에서는 각 프로세스에 얼마만큼의 메모리 공간을 할당할 것인지 결정해야함

### 균등할당

모든 프로세스에게 페이지 프레임을 균등하게 할당하는 방식

### 비례할당

프로세스의 크기에 비례해 할당하는 방식

### 우선순위 할당

당장 CPU에서 실행될 프로세스에 더 많은 프레임을 할당하는 방식



이런 알고리즘만 가지고는 페이지의 참조 특성을 제대로 반영하지 못할 수 있음

반복문 구성시에는 모든 페이지를 한꺼번에 올리는게 좋은데, 반복문을 구성하는 수보다 적은 양의 프레임을 할당한다면 매 반복마다 적어도 한 번 이상의 페이지 부재가 발생하기 때문

최소한으로 필요한 메모리 양은 시간에 따라 달라질 수 있으므로 이를 고려하여 각 프로세스에 할당되는 페이지 프레임의 수를 결정할 필요가 있음



## Global Replacement & Local Replacement

전역교체는 모든 페이지의 프레임이 교체대상이 될 수 있는 방법

지역교체는 현재 수행중인 프로세스에게 할당된 프레임 내에서만 교체될 수 있는 방법

지역교체 방법은 프로세스마다 페이지 프레임을 미리 할당하는 것을 전제로 함

전역교체 방법은 프로세스마다 메모리를 할당하는 것이 아니라 전체 메모리를 각 프로세스가 공유해서 사용하고 교체 알고리즘에 근거해서 할당되는 메모리 양이 가변적으로 변하는 방식



LRU, LFU를 프로세스별로 운영하면 지역교체 방법을 사용하게 되는 것, 그냥 이용하면 전역교체 방법을 사용하게 되는 것

## Thrasing

스레싱: 참조되는 페이지들의 집합을 메모리에 한꺼번에 적재하지 못해 CPU 이용률이 떨어지는 현상 

CPU 이용률이 낮다는 것은 준비 큐가 비는 경우가 발생한다는 것

MPD: 메모리에 동시에 올라가 있는 프로세스의 수 (= 다중 프로그래밍의 정도)

CPU 이용률이 낮다? MPD를 높이면 됨

하지만 MPD가 과도하게 높아지면 각 프로세스에게 할당되는 메모리 지나치게 감소함

MPD를 적절히 조절해서 CPU이용률을 높이는 알고리즘에는 워킹셋, 페이지 부재 빈도 알고리즘이 있음



### 워킹셋 알고리즘

참조되는 페이지들의 집합을 지역성 집합이라 함

이러한 지역성 집합(워킹셋)을 동시에 올리도록 하는 알고리즘이 워킹셋 알고리즘

워킹셋 윈도우내의 모든 페이지를 메모리에 올려놓음

윈도우가 너무 크면 MPD가 감소하여 CPU 이용률이 낮아짐

윈도우가 너무 작으면 지역성 집합을 모두 수용하지 못할 수 있음



### 페이지 부재 빈도 알고리즘

페이지 부재율을 주기적으로 조사하고 이 값에 근거해서 프로세스에 할당할 메모리 양을 동적으로 결정하는 알고리즘

미리 정해놓은 부재 상한선을 넘으면 더 많은 프레임을 추가로 할당해줌

미리 정해놓은 하한값보다 내려가면 올라가 있는 프레임을 스왑아웃 시킴



